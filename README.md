# BIG_DATA_PROJECT-1


# Wikipedia data analysis
In this project we have analyzed the datasets of Wikipedia English article traffic using different tools and obtained the desired results for questions given.

# Problem Statement
The following are the questions analyzed.
1.Which English wikipedia article got the most traffic on January 20, 2021?
2.What English wikipedia article has the largest fraction of its readers follow an internal link to another wikipedia article?
3.What series of wikipedia articles, starting with Hotel California, keeps the largest fraction of its readers clicking on internal links? 
4.Find an example of an English wikipedia article that is relatively more popular in the Americas than elsewhere.
5.Analyze how many users will see the average vandalized wikipedia page before the offending edit is reversed.

# Tools used
>Hadoop
>HDFS
>Yarn
>MapReduce
>Hive
>Tez
>Python
>Git/Github

# Features
1.Find, organize, and format pageviews on any given day.
2.Follow clickstreams to find relative frequencies of different pages.
3.Determine relative popularity of page access methods.
4.Compare yearly popularity of pages.

# Datasets used
>Pageviews Filtered to Human Traffic
https://wikitech.wikimedia.org/wiki/Analytics/Data_Lake/Traffic/Pageviews  
>Monthly Clickstream
https://meta.wikimedia.org/wiki/Research:Wikipedia_clickstream

# Reference
https://github.com/samye760/Wikipedia-Big-Data-Analysis
